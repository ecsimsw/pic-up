## Offset based paging to cursor based paging

기존 Offset 기반의 페이지네이션에서 Cursor 기반의 페이지네이션으로 페이지 네이션 방식을 수정했다.    
아래는 MySql 8.0에서 100만개의 데이터로 그 둘의 성능 차이를 실험해보고 그 결과를 기록한다.

### 1. 쿼리 비교 

#### Offset based
```
select
    product0_.id as id1_1_,
    product0_.name as name2_1_,
    product0_.price as price3_1_,
    product0_.quantity as quantity4_1_ 
from
    product product0_ 
order by
    product0_.id asc,
    product0_.id asc limit ?
```  

#### Cursor based
```
select
    product0_.id as id1_1_,
    product0_.name as name2_1_,
    product0_.price as price3_1_,
    product0_.quantity as quantity4_1_ 
from
    product product0_ 
where
    product0_.id>50 
order by
    product0_.id asc,
    product0_.id asc limit ?
```

### 2. 성능 테스트 1

인덱스가 ID만 걸려있는 상황에서 Full Scan으로 쿼리할 때 실행 계획과 수행 결과를 비교한다.    
데이터는 100만개, 10회 반복하여 처리 속도를 평균 내었다.

#### 2-1 페이지가 작은 경우

위 Offset 기반, 아래 Cursor 기반의 쿼리이다. 실행 계획에서 후자의 경우 필터로 검색 데이터 수가 줄 것을 예상한다. 
```
explain select * from product order by name asc limit 10 offset 0;          // filtered : 100%  
explain select * from product where name > 'a' order by name asc limit 10;  // filtered : 33% 
```

실제 수행에선 그렇게 큰 차이를 보이지 않는다. Offset이 낮은 경우에는 Offset 기반의 페이지네이션이 큰 문제가 되지 않음을 확인할 수 있다.
```
select * from product order by name asc limit 10 offset 0;                   // about : 0.398 sec  
select * from product where name > 'a' order by name asc limit 10;           // about : 0.407 sec 
```

#### 2-2 페이지가 큰 경우

위 Offset 기반, 아래 Cursor 기반의 쿼리이다. 높은 페이지를 임의로 offset 900000, cursor y보다 이름이 큰 경우를 쿼리한다.
```
explain select * from product order by name asc limit 10 offset 900000;     // filtered : 100%
explain select * from product where name > 'y' order by name asc limit 10;  // filtered : 33%
```

실제 수행 결과에서 큰 차이를 보인다. offset은 뒤쪽으로 갈 수록 수행 시간이 크게 늘어난다.     
반면 커서 기반은 페이지가 늘어나도 수행 속도에 문제가 생기지 않으며 오히려 필터링 되는 부분이 많아 수행 시간이 줄어들기까지 한다.
```
select * from product order by name asc limit 10 offset 900000;              // about : 2.504 sec 
select * from product where name > 'y' order by name asc limit 10;           // about : 0.154 sec
```

### 3. 성능 테스트 2

이번엔 인덱스가 걸려있는 상황에서의 성능 차이를 확인하고 싶었다. 커버링 인덱스를 만들고 위와 같은 테스트를 수행한다.

```
ALTER TABLE `mymarket`.`product` ADD INDEX `index2` (`name` ASC, `id` ASC, `quantity` ASC, `price` ASC);  // 2.80 sec
```

#### 3-1 페이지가 작은 경우
```
explain select * from product order by name asc limit 10 offset 0;          // filtered : 100% / full index scan   
explain select * from product where name > 'a' order by name asc limit 10;  // filtered : 100% / index range scan 
```
```
select * from product order by name asc limit 10 offset 0;                   // about : 0.009 sec  
select * from product where name > 'a' order by name asc limit 10;           // about : 0.008 sec 
```

#### 3-2 페이지가 큰 경우
```
explain select * from product order by name asc limit 10 offset 900000;     // filtered : 100% / full index scan
explain select * from product where name > 'y' order by name asc limit 10;  // filtered : 100% / index range scan
```
```
select * from product order by name asc limit 10 offset 900000;              // about : 0.120 sec 
select * from product where name > 'y' order by name asc limit 10;           // about : 0.008 sec
```

마찬가지로 페이지가 큰 경우에서 큰 차이를 보인다.

### Result

<img width="713" alt="image" src="https://github.com/ecsimsw/pic-up/assets/46060746/734c4f33-9b26-4554-a8c6-c02f8dc03c02">

```
select * from product order by name asc limit 10 offset 0;
select * from product order by name asc limit 10 offset 900000;

select * from product where name > 'a' order by name asc limit 10; 
select * from product where name > 'y' order by name asc limit 10; 
```

## Import big data into MYSQL

Importing csv files from a local mysql server is much faster than external environment.

### Check secure file path
```
SELECT @@GLOBAL.secure_file_priv;
```

### Place data csv file on secure file path

#### TIP, You need vagrant plugin for vagrant scp
```
vagrant plugin install vagrant-scp
vagrant scp ${FILE_PATH} ${VM_NAME}:${VM_FILE_PATH}
```

### Load data csv
```
LOAD DATA INFILE "${LOCAL_FILE_PATH}" INTO TABLE ${TABLE_NAME} FIELDS TERMINATED BY ',' ENCLOSED BY '"' LINES TERMINATED BY '\n' IGNORE 1 ROWS;

ex) LOAD DATA INFILE "/var/lib/mysql-files/init-data.csv" INTO TABLE product FIELDS TERMINATED BY ',' ENCLOSED BY '"' LINES TERMINATED BY '\n' IGNORE 1 ROWS;
```

### Data
/*
Generate init data as csv file.

sample data : 10_00_000
file size : 20MB
execution time : 1s

sample data : 100_000_000
file size : 2GB
execution time : 100s
 */
