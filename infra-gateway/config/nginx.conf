worker_processes  1;
error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;

events {
    worker_connections  1024;
}

http {
    geo $apply_limit {
        default           $binary_remote_addr;
        127.0.0.1/24      '';                    # localhost
        183.100.1.179/24  '';                    # prod server
        192.168.0.0/16    '';                    # dev env subnet
    }
    limit_req_zone $apply_limit zone=default_rate_limit:10m rate=5r/s;

    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log         /var/log/nginx/access.log  main;
    sendfile           on;
    keepalive_timeout  65;

    # include            /etc/nginx/conf.d/default.conf;
    include              /etc/nginx/conf.d/route-api.conf;
    include              /etc/nginx/conf.d/route-monitoring.conf;
    include              /etc/nginx/conf.d/route-files.conf;
}

# rate limit
## 1. 제한 타입
### limit_req_zone : 요청 제한
### limit_conn_zone : 커넥션 제한

## 2. 제한 메트릭
### $binary_remote_addr : 클라이언트의 IP를 기준
### $server_name : 서버를 기준으로
### $binary_remote_addr:$uri : 요청 path를 기준으로

## 3. burst
### 최대 제한 요청 수를 넘어선 요청 / 커넥션을 그 값만큼 큐잉하고 처리가 가능한 시점에서 처리한다.

## 4. nodelay
### burst 를 사용하면 사용자의 요청 처리가 늦는다. 그렇다고 burst 만큼 rate 를 올리면 원하는 속도 제한이 불가능하다.
### burst 로 오버된 요청을 큐잉하면서도 오버된 요청을 서버에 바로 보내 처리한다. 대신 queue 에선 원래 처리 가능해야 했던 시점에서 poll이 일어난다.
### 워터파크 미끄럼틀 같은 친구다. 일단 오버된 사람은 떨어트리지 않고 바로 내려보내되, 원래 계획했던 시간만큼 빈 텀을 두어 속도를 조절한다.

## 5. 그 외 옵션
### zone name : zone name
### share memory assign : bucket size (leaky bucket algorithm)
### rate : request / second
### limit_req_status : default 503, to be 429 (Too many requests)
